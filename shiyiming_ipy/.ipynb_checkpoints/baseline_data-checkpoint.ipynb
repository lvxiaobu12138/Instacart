{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading prior\n",
      "loading train\n",
      "loading orders\n",
      "loading products\n",
      "priors (32434489, 4): order_id, product_id, add_to_cart_order, reordered\n",
      "orders (3421083, 7): order_id, user_id, eval_set, order_number, order_dow, order_hour_of_day, days_since_prior_order\n",
      "train (1384617, 4): order_id, product_id, add_to_cart_order, reordered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "IDIR = '../dataset/'\n",
    "\n",
    "\n",
    "print('loading prior')\n",
    "priors = pd.read_csv(IDIR + 'order_products__prior.csv')\n",
    "print('loading train')\n",
    "train = pd.read_csv(IDIR + 'order_products__train.csv')\n",
    "print('loading orders')\n",
    "orders = pd.read_csv(IDIR + 'orders.csv')\n",
    "print('loading products')\n",
    "products = pd.read_csv(IDIR + 'products.csv')\n",
    "\n",
    "print('priors {}: {}'.format(priors.shape, ', '.join(priors.columns)))\n",
    "print('orders {}: {}'.format(orders.shape, ', '.join(orders.columns)))\n",
    "print('train {}: {}'.format(train.shape, ', '.join(train.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimize memory\n"
     ]
    }
   ],
   "source": [
    "# some memory measures for kaggle kernel\n",
    "print('optimize memory')\n",
    "orders.order_dow = orders.order_dow.astype(np.int8)\n",
    "orders.order_hour_of_day = orders.order_hour_of_day.astype(np.int8)\n",
    "orders.order_number = orders.order_number.astype(np.int16)\n",
    "orders.order_id = orders.order_id.astype(np.int32)\n",
    "orders.user_id = orders.user_id.astype(np.int32)\n",
    "orders.days_since_prior_order = orders.days_since_prior_order.astype(np.float32)\n",
    "\n",
    "products.drop(['product_name'], axis=1, inplace=True)\n",
    "products.aisle_id = products.aisle_id.astype(np.int8)\n",
    "products.department_id = products.department_id.astype(np.int8)\n",
    "products.product_id = products.product_id.astype(np.int32)\n",
    "\n",
    "train.reordered = train.reordered.astype(np.int8)\n",
    "train.add_to_cart_order = train.add_to_cart_order.astype(np.int16)\n",
    "\n",
    "priors.order_id = priors.order_id.astype(np.int32)\n",
    "priors.add_to_cart_order = priors.add_to_cart_order.astype(np.int16)\n",
    "priors.reordered = priors.reordered.astype(np.int8)\n",
    "priors.product_id = priors.product_id.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing product f\n"
     ]
    }
   ],
   "source": [
    "print('computing product f')\n",
    "prods = pd.DataFrame()\n",
    "prods['orders'] = priors.groupby(priors.product_id).size().astype(np.float32)\n",
    "prods['reorders'] = priors['reordered'].groupby(priors.product_id).sum().astype(np.float32)\n",
    "prods['reorder_rate'] = (prods.reorders / prods.orders).astype(np.float32)\n",
    "products = products.join(prods, on='product_id')\n",
    "products.set_index('product_id', drop=False, inplace=True)\n",
    "del prods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add order info to priors\n"
     ]
    }
   ],
   "source": [
    "print('add order info to priors')\n",
    "orders.set_index('order_id', inplace=True, drop=False)\n",
    "priors = priors.join(orders, on='order_id', rsuffix='_')\n",
    "priors.drop('order_id_', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing user f\n",
      "user f (206209, 6)\n"
     ]
    }
   ],
   "source": [
    "### user features\n",
    "\n",
    "print('computing user f')\n",
    "usr = pd.DataFrame()\n",
    "usr['average_days_between_orders'] = orders.groupby('user_id')['days_since_prior_order'].mean().astype(np.float32)\n",
    "usr['nb_orders'] = orders.groupby('user_id').size().astype(np.int16)\n",
    "\n",
    "users = pd.DataFrame()\n",
    "users['total_items'] = priors.groupby('user_id').size().astype(np.int16)\n",
    "users['all_products'] = priors.groupby('user_id')['product_id'].apply(set)\n",
    "users['total_distinct_items'] = (users.all_products.map(len)).astype(np.int16)\n",
    "\n",
    "users = users.join(usr)\n",
    "del usr\n",
    "users['average_basket'] = (users.total_items / users.nb_orders).astype(np.float32)\n",
    "gc.collect()\n",
    "print('user f', users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute userXproduct f - this is long...\n",
      "to dataframe (less memory)\n",
      "user X product f 13293564\n"
     ]
    }
   ],
   "source": [
    "### userXproduct features\n",
    "\n",
    "print('compute userXproduct f - this is long...')\n",
    "priors['user_product'] = priors.product_id + priors.user_id * 100000\n",
    "\n",
    "# This was to slow !!\n",
    "#def last_order(order_group):\n",
    "#    ix = order_group.order_number.idxmax\n",
    "#    return order_group.shape[0], order_group.order_id[ix],  order_group.add_to_cart_order.mean()\n",
    "#userXproduct = pd.DataFrame()\n",
    "#userXproduct['tmp'] = df.groupby('user_product').apply(last_order)\n",
    "\n",
    "d= dict()\n",
    "for row in priors.itertuples():\n",
    "    z = row.user_product\n",
    "    if z not in d:\n",
    "        d[z] = (1,\n",
    "                (row.order_number, row.order_id),\n",
    "                row.add_to_cart_order)\n",
    "    else:\n",
    "        d[z] = (d[z][0] + 1,\n",
    "                max(d[z][1], (row.order_number, row.order_id)),\n",
    "                d[z][2] + row.add_to_cart_order)\n",
    "\n",
    "print('to dataframe (less memory)')\n",
    "d = pd.DataFrame.from_dict(d, orient='index')\n",
    "d.columns = ['nb_orders', 'last_order_id', 'sum_pos_in_cart']\n",
    "d.nb_orders = d.nb_orders.astype(np.int16)\n",
    "d.last_order_id = d.last_order_id.map(lambda x: x[1]).astype(np.int32)\n",
    "d.sum_pos_in_cart = d.sum_pos_in_cart.astype(np.int16)\n",
    "   \n",
    "userXproduct = d\n",
    "print('user X product f', len(userXproduct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split orders : train, test\n"
     ]
    }
   ],
   "source": [
    "### train / test orders ###\n",
    "print('split orders : train, test')\n",
    "test_orders = orders[orders.eval_set == 'test']\n",
    "train_orders = orders[orders.eval_set == 'train']\n",
    "\n",
    "train.set_index(['order_id', 'product_id'], inplace=True, drop=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#提出真正的训练集 作为 历史数据的标签\n",
    "train_real=train[train['reordered']==1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### build list of candidate products to reorder, with features ###\n",
    "\n",
    "def features(selected_orders, labels_given=False):\n",
    "    print('build candidate list')\n",
    "    order_list = []\n",
    "    product_list = []\n",
    "    labels = []\n",
    "    i=0\n",
    "    for row in selected_orders.itertuples():\n",
    "        i+=1\n",
    "        if i%10000 == 0: print('order row',i)\n",
    "        order_id = row.order_id\n",
    "        user_id = row.user_id\n",
    "        user_products = users.all_products[user_id]\n",
    "        product_list += user_products\n",
    "        order_list += [order_id] * len(user_products)\n",
    "        if labels_given:\n",
    "            labels += [(order_id, product) in train_real.index for product in user_products]\n",
    "            #labels += [(order_id, product) in train.index for product in user_products]\n",
    "        \n",
    "    df = pd.DataFrame({'order_id':order_list, 'product_id':product_list})\n",
    "    df.order_id = df.order_id.astype(np.int32)\n",
    "    df.product_id = df.product_id.astype(np.int32)\n",
    "    labels = np.array(labels, dtype=np.int8)\n",
    "    del order_list\n",
    "    del product_list\n",
    "    \n",
    "    print('user related features')\n",
    "    df['user_id'] = df.order_id.map(orders.user_id).astype(np.int32)\n",
    "    df['user_total_orders'] = df.user_id.map(users.nb_orders)\n",
    "    df['user_total_items'] = df.user_id.map(users.total_items)\n",
    "    df['total_distinct_items'] = df.user_id.map(users.total_distinct_items)\n",
    "    df['user_average_days_between_orders'] = df.user_id.map(users.average_days_between_orders)\n",
    "    df['user_average_basket'] =  df.user_id.map(users.average_basket)\n",
    "    \n",
    "    print('order related features')\n",
    "    # df['dow'] = df.order_id.map(orders.order_dow)\n",
    "    df['order_hour_of_day'] = df.order_id.map(orders.order_hour_of_day)\n",
    "    df['days_since_prior_order'] = df.order_id.map(orders.days_since_prior_order)\n",
    "    df['days_since_ratio'] = df.days_since_prior_order / df.user_average_days_between_orders\n",
    "    \n",
    "    print('product related features')\n",
    "    df['aisle_id'] = df.product_id.map(products.aisle_id).astype(np.int8)\n",
    "    df['department_id'] = df.product_id.map(products.department_id).astype(np.int8)\n",
    "    df['product_orders'] = df.product_id.map(products.orders).astype(np.float32)\n",
    "    df['product_reorders'] = df.product_id.map(products.reorders).astype(np.float32)\n",
    "    df['product_reorder_rate'] = df.product_id.map(products.reorder_rate)\n",
    "\n",
    "    print('user_X_product related features')\n",
    "    df['z'] = df.user_id * 100000 + df.product_id\n",
    "    df.drop(['user_id'], axis=1, inplace=True)\n",
    "    df['UP_orders'] = df.z.map(userXproduct.nb_orders)\n",
    "    df['UP_orders_ratio'] = (df.UP_orders / df.user_total_orders).astype(np.float32)\n",
    "    df['UP_last_order_id'] = df.z.map(userXproduct.last_order_id)\n",
    "    df['UP_average_pos_in_cart'] = (df.z.map(userXproduct.sum_pos_in_cart) / df.UP_orders).astype(np.float32)\n",
    "    df['UP_reorder_rate'] = (df.UP_orders / df.user_total_orders).astype(np.float32)\n",
    "    df['UP_orders_since_last'] = df.user_total_orders - df.UP_last_order_id.map(orders.order_number)\n",
    "    df['UP_delta_hour_vs_last'] = abs(df.order_hour_of_day - \\\n",
    "                  df.UP_last_order_id.map(orders.order_hour_of_day)).map(lambda x: min(x, 24-x)).astype(np.int8)\n",
    "    #df['UP_same_dow_as_last_order'] = df.UP_last_order_id.map(orders.order_dow) == \\\n",
    "    #                                              df.order_id.map(orders.order_dow)\n",
    "\n",
    "    df.drop(['UP_last_order_id', 'z'], axis=1, inplace=True)\n",
    "    print(df.dtypes)\n",
    "    print(df.memory_usage())\n",
    "    print(train.memory_usage())\n",
    "    print(products.memory_usage())\n",
    "    gc.collect()\n",
    "    return (df, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build candidate list\n",
      "order row 10000\n",
      "order row 20000\n",
      "order row 30000\n",
      "order row 40000\n",
      "order row 50000\n",
      "order row 60000\n",
      "order row 70000\n",
      "order row 80000\n",
      "order row 90000\n",
      "order row 100000\n",
      "order row 110000\n",
      "order row 120000\n",
      "order row 130000\n",
      "user related features\n",
      "order related features\n",
      "product related features\n",
      "user_X_product related features\n",
      "order_id                              int32\n",
      "product_id                            int32\n",
      "user_total_orders                     int16\n",
      "user_total_items                      int16\n",
      "total_distinct_items                  int16\n",
      "user_average_days_between_orders    float32\n",
      "user_average_basket                 float32\n",
      "order_hour_of_day                      int8\n",
      "days_since_prior_order              float32\n",
      "days_since_ratio                    float32\n",
      "aisle_id                               int8\n",
      "department_id                          int8\n",
      "product_orders                      float32\n",
      "product_reorders                    float32\n",
      "product_reorder_rate                float32\n",
      "UP_orders                             int16\n",
      "UP_orders_ratio                     float32\n",
      "UP_average_pos_in_cart              float32\n",
      "UP_reorder_rate                     float32\n",
      "UP_orders_since_last                  int16\n",
      "UP_delta_hour_vs_last                  int8\n",
      "dtype: object\n",
      "Index                                     80\n",
      "order_id                            33898644\n",
      "product_id                          33898644\n",
      "user_total_orders                   16949322\n",
      "user_total_items                    16949322\n",
      "total_distinct_items                16949322\n",
      "user_average_days_between_orders    33898644\n",
      "user_average_basket                 33898644\n",
      "order_hour_of_day                    8474661\n",
      "days_since_prior_order              33898644\n",
      "days_since_ratio                    33898644\n",
      "aisle_id                             8474661\n",
      "department_id                        8474661\n",
      "product_orders                      33898644\n",
      "product_reorders                    33898644\n",
      "product_reorder_rate                33898644\n",
      "UP_orders                           16949322\n",
      "UP_orders_ratio                     33898644\n",
      "UP_average_pos_in_cart              33898644\n",
      "UP_reorder_rate                     33898644\n",
      "UP_orders_since_last                16949322\n",
      "UP_delta_hour_vs_last                8474661\n",
      "dtype: int64\n",
      "Index                59625646\n",
      "order_id             11076936\n",
      "product_id           11076936\n",
      "add_to_cart_order     2769234\n",
      "reordered             1384617\n",
      "dtype: int64\n",
      "Index            1708224\n",
      "product_id        198752\n",
      "aisle_id           49688\n",
      "department_id      49688\n",
      "orders            198752\n",
      "reorders          198752\n",
      "reorder_rate      198752\n",
      "dtype: int64\n",
      "formating for lgb\n",
      "light GBM train :-)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, labels = features(train_orders, labels_given=True)\n",
    "\n",
    "f_to_use = ['user_total_orders', 'user_total_items', 'total_distinct_items',\n",
    "       'user_average_days_between_orders', 'user_average_basket',\n",
    "       'order_hour_of_day', 'days_since_prior_order', 'days_since_ratio',\n",
    "       'aisle_id', 'department_id', 'product_orders', 'product_reorders',\n",
    "       'product_reorder_rate', 'UP_orders', 'UP_orders_ratio',\n",
    "       'UP_average_pos_in_cart', 'UP_reorder_rate', 'UP_orders_since_last',\n",
    "       'UP_delta_hour_vs_last'] # 'dow', 'UP_same_dow_as_last_order'\n",
    "\n",
    "\n",
    "print('formating for lgb')\n",
    "d_train = lgb.Dataset(df_train[f_to_use],\n",
    "                      label=labels,\n",
    "                      categorical_feature=['aisle_id', 'department_id'])  # , 'order_hour_of_day', 'dow'\n",
    "#del df_train\n",
    "gc.collect()\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 96,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 5\n",
    "}\n",
    "ROUNDS = 98\n",
    "\n",
    "print('light GBM train :-)')\n",
    "bst = lgb.train(params, d_train, ROUNDS)\n",
    "#lgb.plot_importance(bst, figsize=(9,20))\n",
    "del d_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_fun(labels, preds):\n",
    "    labels = labels.split(' ')\n",
    "    preds = preds.split(' ')\n",
    "    rr = (np.intersect1d(labels, preds))\n",
    "    precision = np.float(len(rr)) / len(preds)\n",
    "    recall = np.float(len(rr)) / len(labels)\n",
    "    try:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        return (precision, recall, 0.0)\n",
    "    return (precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build candidate list\n",
      "order row 10000\n",
      "order row 20000\n",
      "order row 30000\n",
      "order row 40000\n",
      "order row 50000\n",
      "order row 60000\n",
      "order row 70000\n",
      "user related features\n",
      "order related features\n",
      "product related features\n",
      "user_X_product related features\n",
      "order_id                              int32\n",
      "product_id                            int32\n",
      "user_total_orders                     int16\n",
      "user_total_items                      int16\n",
      "total_distinct_items                  int16\n",
      "user_average_days_between_orders    float32\n",
      "user_average_basket                 float32\n",
      "order_hour_of_day                      int8\n",
      "days_since_prior_order              float32\n",
      "days_since_ratio                    float32\n",
      "aisle_id                               int8\n",
      "department_id                          int8\n",
      "product_orders                      float32\n",
      "product_reorders                    float32\n",
      "product_reorder_rate                float32\n",
      "UP_orders                             int16\n",
      "UP_orders_ratio                     float32\n",
      "UP_average_pos_in_cart              float32\n",
      "UP_reorder_rate                     float32\n",
      "UP_orders_since_last                  int16\n",
      "UP_delta_hour_vs_last                  int8\n",
      "dtype: object\n",
      "Index                                     80\n",
      "order_id                            19333168\n",
      "product_id                          19333168\n",
      "user_total_orders                    9666584\n",
      "user_total_items                     9666584\n",
      "total_distinct_items                 9666584\n",
      "user_average_days_between_orders    19333168\n",
      "user_average_basket                 19333168\n",
      "order_hour_of_day                    4833292\n",
      "days_since_prior_order              19333168\n",
      "days_since_ratio                    19333168\n",
      "aisle_id                             4833292\n",
      "department_id                        4833292\n",
      "product_orders                      19333168\n",
      "product_reorders                    19333168\n",
      "product_reorder_rate                19333168\n",
      "UP_orders                            9666584\n",
      "UP_orders_ratio                     19333168\n",
      "UP_average_pos_in_cart              19333168\n",
      "UP_reorder_rate                     19333168\n",
      "UP_orders_since_last                 9666584\n",
      "UP_delta_hour_vs_last                4833292\n",
      "dtype: int64\n",
      "Index                54382748\n",
      "order_id             11076936\n",
      "product_id           11076936\n",
      "add_to_cart_order     2769234\n",
      "reordered             1384617\n",
      "dtype: int64\n",
      "Index            1708224\n",
      "product_id        198752\n",
      "aisle_id           49688\n",
      "department_id      49688\n",
      "orders            198752\n",
      "reorders          198752\n",
      "reorder_rate      198752\n",
      "dtype: int64\n",
      "light GBM predict\n"
     ]
    }
   ],
   "source": [
    "### build candidates list for test ###\n",
    "\n",
    "df_test, _ = features(test_orders)\n",
    "\n",
    "print('light GBM predict')\n",
    "preds = bst.predict(df_test[f_to_use])\n",
    "\n",
    "df_test['pred'] = preds\n",
    "sub=get_pred_results(df_test,thrshold=0.22)\n",
    "#sub.to_csv('sub.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交叉验证实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_liststr(df_test):\n",
    "    n=1\n",
    "    for row in df_test:\n",
    "        if n==1:\n",
    "            temp=str(row)\n",
    "            n=0\n",
    "             \n",
    "        else:\n",
    "                temp += ' ' + str(row)\n",
    "    return  temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_liststr1(df_test):\n",
    "    n=1\n",
    "    for row in df_test.split(' '):\n",
    "        if n==1:\n",
    "            temp=row\n",
    "            n=0\n",
    "             \n",
    "        else:\n",
    "                temp += ' ' + row\n",
    "    return  temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_pred_results(df_test,thrshold=0.22):\n",
    "    TRESHOLD = thrshold  # guess, should be tuned with crossval on a subset of train data\n",
    "\n",
    "    d = dict()\n",
    "    for row in df_test.itertuples():\n",
    "        if row.pred > TRESHOLD:\n",
    "            try:\n",
    "                d[row.order_id] += ' ' + str(row.product_id)\n",
    "            except:\n",
    "                d[row.order_id] = str(row.product_id)\n",
    "\n",
    "    for order in test_orders.order_id:\n",
    "        if order not in d:\n",
    "            d[order] = 'None'\n",
    "\n",
    "    sub = pd.DataFrame.from_dict(d, orient='index')\n",
    "    sub.reset_index(inplace=True)\n",
    "    sub.columns = ['order_id', 'products']\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:6: FutureWarning: 'order_id' is both a column name and an index level.\n",
      "Defaulting to column but this will raise an ambiguity error in a future version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.402925647787082"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#求得预测值 \n",
    "df_train['pred'] = bst.predict(df_train[f_to_use])\n",
    "train_pred=get_pred_results(df_train,thrshold=0.22)\n",
    "#得到order-id真值 存入一个dataframe\n",
    "lable_train=train[train['reordered']==1].groupby(['order_id'])['product_id'].apply(get_liststr)\n",
    "df_temp=pd.DataFrame({'lable':lable_train,'order_id':lable_train.index})\n",
    "#合表\n",
    "train_pred1=pd.merge(train_pred,df_temp,on=['order_id'])\n",
    "#求F1结果表\n",
    "res = list()\n",
    "for entry in train_pred1.itertuples():\n",
    "    res.append(eval_fun(entry[2], entry[3]))\n",
    "res = pd.DataFrame(np.array(res), columns=['precision', 'recall', 'f1'])\n",
    "res['f1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['temp_index']=df_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n'boosting_type': 'gbdt',\\n    'objective': 'binary',\\n    'metric': {'binary_logloss'},\\n    'num_leaves': 96,\\n    'feature_fraction': 0.9,\\n    'bagging_fraction': 0.95,\\n    'bagging_freq': 5\\n\""
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 96,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 5\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 1: train:0.4032804055797786, test:0.4021021600473585\n",
      "* 2: train:0.4040488157522452, test:0.4006273140813934\n",
      "* 3: train:0.40455864916548656, test:0.39926771769730734\n",
      "ALL: test ALL： 0.403962623499\n"
     ]
    }
   ],
   "source": [
    "#先使用最简单的k-Fold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf=KFold(n_splits=3)    # 定义分成几个组\n",
    "list_f1=[]\n",
    "num=1\n",
    "clf=LGBMClassifier(objective='binary', boosting_type='gbdt')\n",
    "#决定采用手动cv  因为需要了利用合表才能得到F1 传统方法不可以 数组合表 太可怕···\n",
    "#把数组变成切边的形式 判断是 第几次 第一次 和 最后一次 特殊处理 即可\n",
    "\n",
    "for train_index,test_index in kf.split(df_train, labels):\n",
    "    \n",
    "    #train_max=train_index.max()\n",
    "    #train_min=train_index.min()\n",
    "    test_max=test_index.max()+1\n",
    "    test_min=test_index.min()\n",
    "    X_test=df_train[test_min:test_max]\n",
    "    X_train=df_train.drop(test_index)\n",
    "    #X_train,X_test=data_train[train_index],data_train[test_index]\n",
    "    y_train,y_test=labels[train_index],labels[test_index]   \n",
    "    d_train = lgb.Dataset(X_train[f_to_use],\n",
    "                      label=y_train,\n",
    "                      categorical_feature=['aisle_id', 'department_id'])  # , 'order_hour_of_day', 'dow'\n",
    "    bst = lgb.train(params, d_train, ROUNDS)\n",
    "    a=fscore(y_train, X_train,bst)\n",
    "    b=fscore(y_test, X_test,bst)\n",
    "    list_f1.append(a)\n",
    "    print('* {}: train:{}, test:{}'.format(num,a,b))\n",
    "    num+=1\n",
    "    \n",
    "print('ALL:', 'test ALL：',np.mean(list_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: FutureWarning: 'order_id' is both a column name and an index level.\n",
      "Defaulting to column but this will raise an ambiguity error in a future version\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#得到order-id真值 存入一个dataframe\n",
    "lable_train=train[train['reordered']==1].groupby(['order_id'])['product_id'].apply(get_liststr)\n",
    "df_temp=pd.DataFrame({'lable':lable_train,'order_id':lable_train.index})\n",
    "\n",
    "def fscore(y_test, df,bst):\n",
    "    df['pred'] = bst.predict(df[f_to_use])\n",
    "    train_pred=get_pred_results(df,thrshold=0.22)\n",
    "    #合表\n",
    "    train_pred1=pd.merge(train_pred,df_temp,on=['order_id'])\n",
    "    #求F1结果表\n",
    "    res = list()\n",
    "    for entry in train_pred1.itertuples():\n",
    "        res.append(eval_fun(entry[2], entry[3]))\n",
    "    res = pd.DataFrame(np.array(res), columns=['precision', 'recall', 'f1'])\n",
    "    return res['f1'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
