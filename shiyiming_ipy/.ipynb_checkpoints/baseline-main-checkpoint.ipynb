{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading prior\n",
      "loading train\n",
      "loading orders\n",
      "loading products\n",
      "priors (32434489, 4): order_id, product_id, add_to_cart_order, reordered\n",
      "orders (3421083, 7): order_id, user_id, eval_set, order_number, order_dow, order_hour_of_day, days_since_prior_order\n",
      "train (1384617, 4): order_id, product_id, add_to_cart_order, reordered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "IDIR = '../dataset/'\n",
    "\n",
    "\n",
    "print('loading prior')\n",
    "priors = pd.read_csv(IDIR + 'order_products__prior.csv')\n",
    "print('loading train')\n",
    "train = pd.read_csv(IDIR + 'order_products__train.csv')\n",
    "print('loading orders')\n",
    "orders = pd.read_csv(IDIR + 'orders.csv')\n",
    "print('loading products')\n",
    "products = pd.read_csv(IDIR + 'products.csv')\n",
    "\n",
    "print('priors {}: {}'.format(priors.shape, ', '.join(priors.columns)))\n",
    "print('orders {}: {}'.format(orders.shape, ', '.join(orders.columns)))\n",
    "print('train {}: {}'.format(train.shape, ', '.join(train.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimize memory\n"
     ]
    }
   ],
   "source": [
    "# some memory measures for kaggle kernel\n",
    "print('optimize memory')\n",
    "orders.order_dow = orders.order_dow.astype(np.int8)\n",
    "orders.order_hour_of_day = orders.order_hour_of_day.astype(np.int8)\n",
    "orders.order_number = orders.order_number.astype(np.int16)\n",
    "orders.order_id = orders.order_id.astype(np.int32)\n",
    "orders.user_id = orders.user_id.astype(np.int32)\n",
    "orders.days_since_prior_order = orders.days_since_prior_order.astype(np.float32)\n",
    "\n",
    "products.drop(['product_name'], axis=1, inplace=True)\n",
    "products.aisle_id = products.aisle_id.astype(np.int8)\n",
    "products.department_id = products.department_id.astype(np.int8)\n",
    "products.product_id = products.product_id.astype(np.int32)\n",
    "\n",
    "train.reordered = train.reordered.astype(np.int8)\n",
    "train.add_to_cart_order = train.add_to_cart_order.astype(np.int16)\n",
    "\n",
    "priors.order_id = priors.order_id.astype(np.int32)\n",
    "priors.add_to_cart_order = priors.add_to_cart_order.astype(np.int16)\n",
    "priors.reordered = priors.reordered.astype(np.int8)\n",
    "priors.product_id = priors.product_id.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing product f\n"
     ]
    }
   ],
   "source": [
    "print('computing product f')\n",
    "prods = pd.DataFrame()\n",
    "prods['orders'] = priors.groupby(priors.product_id).size().astype(np.float32)\n",
    "prods['reorders'] = priors['reordered'].groupby(priors.product_id).sum().astype(np.float32)\n",
    "prods['reorder_rate'] = (prods.reorders / prods.orders).astype(np.float32)\n",
    "products = products.join(prods, on='product_id')\n",
    "products.set_index('product_id', drop=False, inplace=True)\n",
    "del prods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products.to_pickle('products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add order info to priors\n"
     ]
    }
   ],
   "source": [
    "print('add order info to priors')\n",
    "orders.set_index('order_id', inplace=True, drop=False)\n",
    "priors = priors.join(orders, on='order_id', rsuffix='_')\n",
    "priors.drop('order_id_', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "priors.to_pickle('priors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing user f\n",
      "user f (206209, 6)\n"
     ]
    }
   ],
   "source": [
    "### user features\n",
    "\n",
    "print('computing user f')\n",
    "usr = pd.DataFrame()\n",
    "usr['average_days_between_orders'] = orders.groupby('user_id')['days_since_prior_order'].mean().astype(np.float32)\n",
    "usr['nb_orders'] = orders.groupby('user_id').size().astype(np.int16)\n",
    "\n",
    "users = pd.DataFrame()\n",
    "users['total_items'] = priors.groupby('user_id').size().astype(np.int16)\n",
    "users['all_products'] = priors.groupby('user_id')['product_id'].apply(set)\n",
    "users['total_distinct_items'] = (users.all_products.map(len)).astype(np.int16)\n",
    "\n",
    "users = users.join(usr)\n",
    "del usr\n",
    "users['average_basket'] = (users.total_items / users.nb_orders).astype(np.float32)\n",
    "gc.collect()\n",
    "print('user f', users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users.to_pickle('users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute userXproduct f - this is long...\n",
      "to dataframe (less memory)\n",
      "user X product f 13293564\n"
     ]
    }
   ],
   "source": [
    "### userXproduct features\n",
    "\n",
    "print('compute userXproduct f - this is long...')\n",
    "priors['user_product'] = priors.product_id + priors.user_id * 100000\n",
    "\n",
    "# This was to slow !!\n",
    "#def last_order(order_group):\n",
    "#    ix = order_group.order_number.idxmax\n",
    "#    return order_group.shape[0], order_group.order_id[ix],  order_group.add_to_cart_order.mean()\n",
    "#userXproduct = pd.DataFrame()\n",
    "#userXproduct['tmp'] = df.groupby('user_product').apply(last_order)\n",
    "\n",
    "d= dict()\n",
    "for row in priors.itertuples():\n",
    "    z = row.user_product\n",
    "    if z not in d:\n",
    "        d[z] = (1,\n",
    "                (row.order_number, row.order_id),\n",
    "                row.add_to_cart_order)\n",
    "    else:\n",
    "        d[z] = (d[z][0] + 1,\n",
    "                max(d[z][1], (row.order_number, row.order_id)),\n",
    "                d[z][2] + row.add_to_cart_order)\n",
    "\n",
    "print('to dataframe (less memory)')\n",
    "d = pd.DataFrame.from_dict(d, orient='index')\n",
    "d.columns = ['nb_orders', 'last_order_id', 'sum_pos_in_cart']\n",
    "d.nb_orders = d.nb_orders.astype(np.int16)\n",
    "d.last_order_id = d.last_order_id.map(lambda x: x[1]).astype(np.int32)\n",
    "d.sum_pos_in_cart = d.sum_pos_in_cart.astype(np.int16)\n",
    "   \n",
    "userXproduct = d\n",
    "print('user X product f', len(userXproduct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userXproduct.to_pickle('userXproduct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split orders : train, test\n"
     ]
    }
   ],
   "source": [
    "### train / test orders ###\n",
    "print('split orders : train, test')\n",
    "test_orders = orders[orders.eval_set == 'test']\n",
    "train_orders = orders[orders.eval_set == 'train']\n",
    "\n",
    "train.set_index(['order_id', 'product_id'], inplace=True, drop=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#提出真正的训练集 作为 历史数据的标签\n",
    "train_real=train[train['reordered']==1].copy()\n",
    "### build list of candidate products to reorder, with features ###\n",
    "\n",
    "def features(selected_orders, labels_given=False):\n",
    "    print('build candidate list')\n",
    "    order_list = []\n",
    "    product_list = []\n",
    "    labels = []\n",
    "    i=0\n",
    "    for row in selected_orders.itertuples():\n",
    "        i+=1\n",
    "        if i%10000 == 0: print('order row',i)\n",
    "        order_id = row.order_id\n",
    "        user_id = row.user_id\n",
    "        user_products = users.all_products[user_id]\n",
    "        product_list += user_products\n",
    "        order_list += [order_id] * len(user_products)\n",
    "        if labels_given:\n",
    "            labels += [(order_id, product) in train_real.index for product in user_products]\n",
    "            #labels += [(order_id, product) in train.index for product in user_products]\n",
    "        \n",
    "    df = pd.DataFrame({'order_id':order_list, 'product_id':product_list})\n",
    "    df.order_id = df.order_id.astype(np.int32)\n",
    "    df.product_id = df.product_id.astype(np.int32)\n",
    "    labels = np.array(labels, dtype=np.int8)\n",
    "    del order_list\n",
    "    del product_list\n",
    "    \n",
    "    print('user related features')\n",
    "    df['user_id'] = df.order_id.map(orders.user_id).astype(np.int32)\n",
    "    df['user_total_orders'] = df.user_id.map(users.nb_orders)\n",
    "    df['user_total_items'] = df.user_id.map(users.total_items)\n",
    "    df['total_distinct_items'] = df.user_id.map(users.total_distinct_items)\n",
    "    df['user_average_days_between_orders'] = df.user_id.map(users.average_days_between_orders)\n",
    "    df['user_average_basket'] =  df.user_id.map(users.average_basket)\n",
    "    \n",
    "    print('order related features')\n",
    "    # df['dow'] = df.order_id.map(orders.order_dow)\n",
    "    df['order_hour_of_day'] = df.order_id.map(orders.order_hour_of_day)\n",
    "    df['days_since_prior_order'] = df.order_id.map(orders.days_since_prior_order)\n",
    "    df['days_since_ratio'] = df.days_since_prior_order / df.user_average_days_between_orders\n",
    "    \n",
    "    print('product related features')\n",
    "    df['aisle_id'] = df.product_id.map(products.aisle_id).astype(np.int8)\n",
    "    df['department_id'] = df.product_id.map(products.department_id).astype(np.int8)\n",
    "    df['product_orders'] = df.product_id.map(products.orders).astype(np.float32)\n",
    "    df['product_reorders'] = df.product_id.map(products.reorders).astype(np.float32)\n",
    "    df['product_reorder_rate'] = df.product_id.map(products.reorder_rate)\n",
    "\n",
    "    print('user_X_product related features')\n",
    "    df['z'] = df.user_id * 100000 + df.product_id\n",
    "    df.drop(['user_id'], axis=1, inplace=True)\n",
    "    df['UP_orders'] = df.z.map(userXproduct.nb_orders)\n",
    "    df['UP_orders_ratio'] = (df.UP_orders / df.user_total_orders).astype(np.float32)\n",
    "    df['UP_last_order_id'] = df.z.map(userXproduct.last_order_id)\n",
    "    df['UP_average_pos_in_cart'] = (df.z.map(userXproduct.sum_pos_in_cart) / df.UP_orders).astype(np.float32)\n",
    "    df['UP_reorder_rate'] = (df.UP_orders / df.user_total_orders).astype(np.float32)\n",
    "    df['UP_orders_since_last'] = df.user_total_orders - df.UP_last_order_id.map(orders.order_number)\n",
    "    df['UP_delta_hour_vs_last'] = abs(df.order_hour_of_day - \\\n",
    "                  df.UP_last_order_id.map(orders.order_hour_of_day)).map(lambda x: min(x, 24-x)).astype(np.int8)\n",
    "    #df['UP_same_dow_as_last_order'] = df.UP_last_order_id.map(orders.order_dow) == \\\n",
    "    #                                              df.order_id.map(orders.order_dow)\n",
    "\n",
    "    df.drop(['UP_last_order_id', 'z'], axis=1, inplace=True)\n",
    "    print(df.dtypes)\n",
    "    print(df.memory_usage())\n",
    "    print(train.memory_usage())\n",
    "    print(products.memory_usage())\n",
    "    gc.collect()\n",
    "    return (df, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_fun(labels, preds):\n",
    "    labels = labels.split(' ')\n",
    "    preds = preds.split(' ')\n",
    "    rr = (np.intersect1d(labels, preds))\n",
    "    precision = np.float(len(rr)) / len(preds)\n",
    "    recall = np.float(len(rr)) / len(labels)\n",
    "    try:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        return (precision, recall, 0.0)\n",
    "    return (precision, recall, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交叉验证实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#一些辅助函数 为了交叉验证 需要把同一订单号的 物品 合为一个\n",
    "def get_liststr(df_test):\n",
    "    n=1\n",
    "    for row in df_test:\n",
    "        if n==1:\n",
    "            temp=str(row)\n",
    "            n=0\n",
    "             \n",
    "        else:\n",
    "                temp += ' ' + str(row)\n",
    "    return  temp\n",
    "\n",
    "def get_liststr1(df_test):\n",
    "    n=1\n",
    "    for row in df_test.split(' '):\n",
    "        if n==1:\n",
    "            temp=row\n",
    "            n=0\n",
    "             \n",
    "        else:\n",
    "                temp += ' ' + row\n",
    "    return  temp\n",
    "#把预测结果 通过阈值 挑选出来 放入一个字符串中 ‘product1 2 3 4···’\n",
    "def get_pred_results(df_test,thrshold=0.22):\n",
    "    TRESHOLD = thrshold  # guess, should be tuned with crossval on a subset of train data\n",
    "\n",
    "    d = dict()\n",
    "    for row in df_test.itertuples():\n",
    "        if row.pred > TRESHOLD:\n",
    "            try:\n",
    "                d[row.order_id] += ' ' + str(row.product_id)\n",
    "            except:\n",
    "                d[row.order_id] = str(row.product_id)\n",
    "\n",
    "    for order in test_orders.order_id:\n",
    "        if order not in d:\n",
    "            d[order] = 'None'\n",
    "\n",
    "    sub = pd.DataFrame.from_dict(d, orient='index')\n",
    "    sub.reset_index(inplace=True)\n",
    "    sub.columns = ['order_id', 'products']\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train['labels']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.to_pickle('df_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build candidate list\n",
      "order row 10000\n",
      "order row 20000\n",
      "order row 30000\n",
      "order row 40000\n",
      "order row 50000\n",
      "order row 60000\n",
      "order row 70000\n",
      "order row 80000\n",
      "order row 90000\n",
      "order row 100000\n",
      "order row 110000\n",
      "order row 120000\n",
      "order row 130000\n",
      "user related features\n",
      "order related features\n",
      "product related features\n",
      "user_X_product related features\n",
      "order_id                              int32\n",
      "product_id                            int32\n",
      "user_total_orders                     int16\n",
      "user_total_items                      int16\n",
      "total_distinct_items                  int16\n",
      "user_average_days_between_orders    float32\n",
      "user_average_basket                 float32\n",
      "order_hour_of_day                      int8\n",
      "days_since_prior_order              float32\n",
      "days_since_ratio                    float32\n",
      "aisle_id                               int8\n",
      "department_id                          int8\n",
      "product_orders                      float32\n",
      "product_reorders                    float32\n",
      "product_reorder_rate                float32\n",
      "UP_orders                             int16\n",
      "UP_orders_ratio                     float32\n",
      "UP_average_pos_in_cart              float32\n",
      "UP_reorder_rate                     float32\n",
      "UP_orders_since_last                  int16\n",
      "UP_delta_hour_vs_last                  int8\n",
      "dtype: object\n",
      "Index                                     80\n",
      "order_id                            33898644\n",
      "product_id                          33898644\n",
      "user_total_orders                   16949322\n",
      "user_total_items                    16949322\n",
      "total_distinct_items                16949322\n",
      "user_average_days_between_orders    33898644\n",
      "user_average_basket                 33898644\n",
      "order_hour_of_day                    8474661\n",
      "days_since_prior_order              33898644\n",
      "days_since_ratio                    33898644\n",
      "aisle_id                             8474661\n",
      "department_id                        8474661\n",
      "product_orders                      33898644\n",
      "product_reorders                    33898644\n",
      "product_reorder_rate                33898644\n",
      "UP_orders                           16949322\n",
      "UP_orders_ratio                     33898644\n",
      "UP_average_pos_in_cart              33898644\n",
      "UP_reorder_rate                     33898644\n",
      "UP_orders_since_last                16949322\n",
      "UP_delta_hour_vs_last                8474661\n",
      "dtype: int64\n",
      "Index                12439708\n",
      "order_id             11076936\n",
      "product_id           11076936\n",
      "add_to_cart_order     2769234\n",
      "reordered             1384617\n",
      "dtype: int64\n",
      "Index            1708224\n",
      "product_id        198752\n",
      "aisle_id           49688\n",
      "department_id      49688\n",
      "orders            198752\n",
      "reorders          198752\n",
      "reorder_rate      198752\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_train, labels = features(train_orders, labels_given=True)\n",
    "\n",
    "f_to_use = ['user_total_orders', 'user_total_items', 'total_distinct_items',\n",
    "       'user_average_days_between_orders', 'user_average_basket',\n",
    "       'order_hour_of_day', 'days_since_prior_order', 'days_since_ratio',\n",
    "       'aisle_id', 'department_id', 'product_orders', 'product_reorders',\n",
    "       'product_reorder_rate', 'UP_orders', 'UP_orders_ratio',\n",
    "       'UP_average_pos_in_cart', 'UP_reorder_rate', 'UP_orders_since_last',\n",
    "       'UP_delta_hour_vs_last'] # 'dow', 'UP_same_dow_as_last_order'\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 96,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 5\n",
    "}\n",
    "ROUNDS = 98\n",
    "\n",
    "#lgb.plot_importance(bst, figsize=(9,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: FutureWarning: 'order_id' is both a column name and an index level.\n",
      "Defaulting to column but this will raise an ambiguity error in a future version\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#得到order-id真值 存入一个dataframe\n",
    "lable_train=train[train['reordered']==1].groupby(['order_id'])['product_id'].apply(get_liststr)\n",
    "df_temp=pd.DataFrame({'lable':lable_train,'order_id':lable_train.index})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "file must have a 'write' attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d3c50e0be50a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_temp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(self, path, compression)\u001b[0m\n\u001b[1;32m   1376\u001b[0m         \"\"\"\n\u001b[1;32m   1377\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpickle\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_clipboard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexcel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(obj, path, compression)\u001b[0m\n\u001b[1;32m     27\u001b[0m                         is_text=False)\n\u001b[1;32m     28\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mpkl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpkl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_f\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: file must have a 'write' attribute"
     ]
    }
   ],
   "source": [
    "df_temp.to_pickle('df_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build candidate list\n",
      "order row 10000\n",
      "order row 20000\n",
      "order row 30000\n",
      "order row 40000\n",
      "order row 50000\n",
      "order row 60000\n",
      "order row 70000\n",
      "user related features\n",
      "order related features\n",
      "product related features\n",
      "user_X_product related features\n",
      "order_id                              int32\n",
      "product_id                            int32\n",
      "user_total_orders                     int16\n",
      "user_total_items                      int16\n",
      "total_distinct_items                  int16\n",
      "user_average_days_between_orders    float32\n",
      "user_average_basket                 float32\n",
      "order_hour_of_day                      int8\n",
      "days_since_prior_order              float32\n",
      "days_since_ratio                    float32\n",
      "aisle_id                               int8\n",
      "department_id                          int8\n",
      "product_orders                      float32\n",
      "product_reorders                    float32\n",
      "product_reorder_rate                float32\n",
      "UP_orders                             int16\n",
      "UP_orders_ratio                     float32\n",
      "UP_average_pos_in_cart              float32\n",
      "UP_reorder_rate                     float32\n",
      "UP_orders_since_last                  int16\n",
      "UP_delta_hour_vs_last                  int8\n",
      "dtype: object\n",
      "Index                                     80\n",
      "order_id                            19333168\n",
      "product_id                          19333168\n",
      "user_total_orders                    9666584\n",
      "user_total_items                     9666584\n",
      "total_distinct_items                 9666584\n",
      "user_average_days_between_orders    19333168\n",
      "user_average_basket                 19333168\n",
      "order_hour_of_day                    4833292\n",
      "days_since_prior_order              19333168\n",
      "days_since_ratio                    19333168\n",
      "aisle_id                             4833292\n",
      "department_id                        4833292\n",
      "product_orders                      19333168\n",
      "product_reorders                    19333168\n",
      "product_reorder_rate                19333168\n",
      "UP_orders                            9666584\n",
      "UP_orders_ratio                     19333168\n",
      "UP_average_pos_in_cart              19333168\n",
      "UP_reorder_rate                     19333168\n",
      "UP_orders_since_last                 9666584\n",
      "UP_delta_hour_vs_last                4833292\n",
      "dtype: int64\n",
      "Index                12439708\n",
      "order_id             11076936\n",
      "product_id           11076936\n",
      "add_to_cart_order     2769234\n",
      "reordered             1384617\n",
      "dtype: int64\n",
      "Index            1708224\n",
      "product_id        198752\n",
      "aisle_id           49688\n",
      "department_id      49688\n",
      "orders            198752\n",
      "reorders          198752\n",
      "reorder_rate      198752\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_test, _ = features(test_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.to_pickle('df_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'pandas.core.frame.Pandas'>: it's not found as pandas.core.frame.Pandas",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36m_getattribute\u001b[0;34m(obj, name)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mparent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas.core.frame' has no attribute 'Pandas'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave_global\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0mobj2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_getattribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36m_getattribute\u001b[0;34m(obj, name)\u001b[0m\n\u001b[1;32m    271\u001b[0m             raise AttributeError(\"Can't get attribute {!r} on {!r}\"\n\u001b[0;32m--> 272\u001b[0;31m                                  .format(name, obj))\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'Pandas' on <module 'pandas.core.frame' from 'D:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\frame.py'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a92a50906fd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdill\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdill\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data.pickle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\dill\\dill.py\u001b[0m in \u001b[0;36mdump_session\u001b[0;34m(filename, main, byref)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recurse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;31m# disable pickling recursion for globals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m  \u001b[1;31m# is best indicator of when pickling a session\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_framing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Call unbound method with explicit self\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\dill\\dill.py\u001b[0m in \u001b[0;36msave_module\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1166\u001b[0m                 + [\"__builtins__\", \"__loader__\"]]\n\u001b[1;32m   1167\u001b[0m             pickler.save_reduce(_import_module, (obj.__name__,), obj=obj,\n\u001b[0;32m-> 1168\u001b[0;31m                                 state=_main_dict)\n\u001b[0m\u001b[1;32m   1169\u001b[0m             \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"# M1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Call unbound method with explicit self\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\dill\\dill.py\u001b[0m in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[1;31m# we only care about session the first pass thru\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0mpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0mStockPickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"# D2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[1;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    603\u001b[0m                     \"args[0] from __newobj__ args has the wrong class\")\n\u001b[1;32m    604\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m             \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNEWOBJ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Call unbound method with explicit self\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\dill\\dill.py\u001b[0m in \u001b[0;36msave_type\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1229\u001b[0m        \u001b[1;31m#print (\"%s\\n%s\" % (type(obj), obj.__name__))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m        \u001b[1;31m#print (\"%s\\n%s\" % (obj.__bases__, obj.__dict__))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m         \u001b[0mStockPickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_global\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"# T4\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave_global\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    920\u001b[0m             raise PicklingError(\n\u001b[1;32m    921\u001b[0m                 \u001b[1;34m\"Can't pickle %r: it's not found as %s.%s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 (obj, module_name, name))\n\u001b[0m\u001b[1;32m    923\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mobj2\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class 'pandas.core.frame.Pandas'>: it's not found as pandas.core.frame.Pandas"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "dill.dump_session(\"data.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dill.load_session(\"data.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fscore(df,bst,alpha):\n",
    "    df['pred'] = bst.predict(df[f_to_use])\n",
    "    train_pred=get_pred_results(df,thrshold=alpha)\n",
    "    #合表\n",
    "    train_pred1=pd.merge(train_pred,df_temp,on=['order_id'])\n",
    "    #求F1结果表\n",
    "    res = list()\n",
    "    for entry in train_pred1.itertuples():\n",
    "        res.append(eval_fun(entry[2], entry[3]))\n",
    "    res = pd.DataFrame(np.array(res), columns=['precision', 'recall', 'f1'])\n",
    "    return res['f1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fscore_xgb(df,bst,alpha):\n",
    "    d_d=xgb.DMatrix(df[f_to_use])\n",
    "    df['pred'] = bst.predict(d_d)\n",
    "    train_pred=get_pred_results(df,thrshold=alpha)\n",
    "    #合表\n",
    "    train_pred1=pd.merge(train_pred,df_temp,on=['order_id'])\n",
    "    #求F1结果表\n",
    "    res = list()\n",
    "    for entry in train_pred1.itertuples():\n",
    "        res.append(eval_fun(entry[2], entry[3]))\n",
    "    res = pd.DataFrame(np.array(res), columns=['precision', 'recall', 'f1'])\n",
    "    return res['f1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 1: train:0.4032804055797786, test:0.4021021600473585\n",
      "* 2: train:0.4040488157522452, test:0.4006273140813934\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-56ce99bfe104>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                       \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                       categorical_feature=['aisle_id', 'department_id'])  # , 'order_hour_of_day', 'dow'\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mbst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mROUNDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.22\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.22\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm-0.1-py3.6.egg\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, callbacks)\u001b[0m\n\u001b[1;32m    178\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm-0.1-py3.6.egg\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1353\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1354\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1355\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1356\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#先使用最简单的k-Fold\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "kf=KFold(n_splits=3)    # 定义分成几个组\n",
    "list_f1=[]\n",
    "num=1\n",
    "#clf=LGBMClassifier(objective='binary', boosting_type='gbdt')\n",
    "#决定采用手动cv  因为需要了利用合表才能得到F1 传统方法不可以 数组合表 太可怕···\n",
    "#把数组变成切边的形式  即可\n",
    "import timeit\n",
    "start=timeit.default_timer()\n",
    "\n",
    "for train_index,test_index in kf.split(df_train, labels):\n",
    "    \n",
    "    #train_max=train_index.max()\n",
    "    #train_min=train_index.min()\n",
    "    test_max=test_index.max()+1\n",
    "    test_min=test_index.min()\n",
    "    X_test=df_train[test_min:test_max]\n",
    "    X_train=df_train.drop(test_index)\n",
    "    #X_train,X_test=data_train[train_index],data_train[test_index]\n",
    "    y_train,y_test=labels[train_index],labels[test_index]   \n",
    "    d_train = lgb.Dataset(X_train[f_to_use],\n",
    "                      label=y_train,\n",
    "                      categorical_feature=['aisle_id', 'department_id'])  # , 'order_hour_of_day', 'dow'\n",
    "    bst = lgb.train(params, d_train, ROUNDS)\n",
    "    a=fscore(X_train,bst,0.22)\n",
    "    b=fscore(X_test,bst,0.22)\n",
    "    list_f1.append(a)\n",
    "    print('* {}: train:{}, test:{}'.format(num,a,b))\n",
    "    num+=1\n",
    "    \n",
    "print('ALL:', 'test ALL：',np.mean(list_f1))\n",
    "end = timeit.default_timer()\n",
    "print('cost time:'+str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start cv :-) long time```\n",
      "* 1: train:0.4034783079370348, test:0.40158312081066794\n",
      "* 2: train:0.40475417027937466, test:0.4004004778011058\n",
      "* 3: train:0.40515964740531696, test:0.3989556774690958\n",
      "ALL: test ALL： 0.404464041874\n",
      "cost time:1167.8051605892288\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#先使用最简单的k-Fold\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb\n",
    "params_xgb ={\n",
    "  \"objective\"  : \"reg:logistic\",\n",
    "  \"eval_metric\"   : \"logloss\",\n",
    "  \"eta\"    :0.1,\n",
    "  \"max_depth\"   : 8,\n",
    "  \"min_child_weight\"  : 10,\n",
    "  \"gamma\"             : 0.70,\n",
    "  \"subsample\"          : 0.77,\n",
    "  \"colsample_bytree\"    : 0.95,\n",
    "  \"alpha\"             : 2e-05,\n",
    "  \"lambda\"            : 10\n",
    "        }\n",
    "kf=KFold(n_splits=3)    # 定义分成几个组\n",
    "list_f1=[]\n",
    "num=1\n",
    "\n",
    "#clf=LGBMClassifier(objective='binary', boosting_type='gbdt')\n",
    "#决定采用手动cv  因为需要了利用合表才能得到F1 传统方法不可以 数组合表 太可怕···\n",
    "#把数组变成切边的形式  即可\n",
    "import timeit\n",
    "start=timeit.default_timer()\n",
    "print('start cv :-) long time```')\n",
    "for train_index,test_index in kf.split(df_train, labels):\n",
    "    \n",
    "    test_max=test_index.max()+1\n",
    "    test_min=test_index.min()\n",
    "    X_test=df_train[test_min:test_max]\n",
    "    X_train=df_train.drop(test_index)\n",
    "    y_train,y_test=labels[train_index],labels[test_index]   \n",
    "    d_train = xgb.DMatrix(X_train[f_to_use],\n",
    "                      label=y_train)\n",
    "    \n",
    "    bst = xgb.train(params_xgb, d_train, ROUNDS)\n",
    "    a=fscore_xgb(X_train,bst,0.22)\n",
    "    b=fscore_xgb(X_test,bst,0.22)\n",
    "    list_f1.append(a)\n",
    "    print('* {}: train:{}, test:{}'.format(num,a,b))\n",
    "    num+=1\n",
    "    \n",
    "print('ALL:', 'test ALL：',np.mean(list_f1))\n",
    "end = timeit.default_timer()\n",
    "print('cost time:'+str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del d_train\n",
    "del X_test\n",
    "del X_train\n",
    "del y_train\n",
    "del y_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build candidate list\n",
      "order row 10000\n",
      "order row 20000\n",
      "order row 30000\n",
      "order row 40000\n",
      "order row 50000\n",
      "order row 60000\n",
      "order row 70000\n",
      "user related features\n",
      "order related features\n",
      "product related features\n",
      "user_X_product related features\n",
      "order_id                              int32\n",
      "product_id                            int32\n",
      "user_total_orders                     int16\n",
      "user_total_items                      int16\n",
      "total_distinct_items                  int16\n",
      "user_average_days_between_orders    float32\n",
      "user_average_basket                 float32\n",
      "order_hour_of_day                      int8\n",
      "days_since_prior_order              float32\n",
      "days_since_ratio                    float32\n",
      "aisle_id                               int8\n",
      "department_id                          int8\n",
      "product_orders                      float32\n",
      "product_reorders                    float32\n",
      "product_reorder_rate                float32\n",
      "UP_orders                             int16\n",
      "UP_orders_ratio                     float32\n",
      "UP_average_pos_in_cart              float32\n",
      "UP_reorder_rate                     float32\n",
      "UP_orders_since_last                  int16\n",
      "UP_delta_hour_vs_last                  int8\n",
      "dtype: object\n",
      "Index                                     80\n",
      "order_id                            19333168\n",
      "product_id                          19333168\n",
      "user_total_orders                    9666584\n",
      "user_total_items                     9666584\n",
      "total_distinct_items                 9666584\n",
      "user_average_days_between_orders    19333168\n",
      "user_average_basket                 19333168\n",
      "order_hour_of_day                    4833292\n",
      "days_since_prior_order              19333168\n",
      "days_since_ratio                    19333168\n",
      "aisle_id                             4833292\n",
      "department_id                        4833292\n",
      "product_orders                      19333168\n",
      "product_reorders                    19333168\n",
      "product_reorder_rate                19333168\n",
      "UP_orders                            9666584\n",
      "UP_orders_ratio                     19333168\n",
      "UP_average_pos_in_cart              19333168\n",
      "UP_reorder_rate                     19333168\n",
      "UP_orders_since_last                 9666584\n",
      "UP_delta_hour_vs_last                4833292\n",
      "dtype: int64\n",
      "Index                12439726\n",
      "order_id             11076936\n",
      "product_id           11076936\n",
      "add_to_cart_order     2769234\n",
      "reordered             1384617\n",
      "dtype: int64\n",
      "Index            1708224\n",
      "product_id        198752\n",
      "aisle_id           49688\n",
      "department_id      49688\n",
      "orders            198752\n",
      "reorders          198752\n",
      "reorder_rate      198752\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### build candidates list for test ###\n",
    "\n",
    "#前面搞好了 \n",
    "#df_test, _ = features(test_orders)\n",
    "\n",
    "#clf.fit(df_train[f_to_use],labels)\n",
    "d_train = xgb.DMatrix(df_train[f_to_use],label=labels)\n",
    "d_d=xgb.DMatrix(df_test[f_to_use])   \n",
    "\n",
    "bst = xgb.train(params_xgb, d_train, ROUNDS)\n",
    "df_test['pred'] = bst.predict(d_d)\n",
    "\n",
    "sub=get_pred_results(df_test,0.22)\n",
    "#sub.to_csv('sub.csv', index=False)\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "sub.to_csv('xgb_results_{}.{}.{}.csv'.format(\n",
    "    str(now.date()),\n",
    "    str(now.hour),\n",
    "    str(now.minute)\n",
    "), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
